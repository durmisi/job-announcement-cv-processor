import os
from azure.ai.inference import ChatCompletionsClient
from azure.core.credentials import AzureKeyCredential
from . import LLMClient

class GitHubModelsClient(LLMClient):
    def __init__(self):
        self.client = ChatCompletionsClient(
            endpoint="https://models.inference.ai.azure.com",
            credential=AzureKeyCredential(os.getenv("GITHUB_TOKEN"))
        )
        self.model = os.getenv("LLM_MODEL", "gpt-4o-mini")

    def generate_response(self, prompt: str) -> str:
        response = self.client.complete(
            messages=[{"role": "user", "content": prompt}],
            model=self.model
        )
        return response.choices[0].message.content

# Generated by Copilot