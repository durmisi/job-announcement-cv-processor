from fastapi import APIRouter, HTTPException, UploadFile, File, Form
import json
import logging
import mimetypes
import re
from llm.factory import get_llm_client
from utils.text_extraction import extract_text_from_file
from langchain_core.messages import HumanMessage

router = APIRouter()

logger = logging.getLogger(__name__)

@router.post("/analyze")
async def analyze_cv(cv_file: UploadFile = File(...), job_content: str = Form(...)):
    if not cv_file:
        raise HTTPException(status_code=400, detail="CV file is required")
    if not job_content.strip():
        raise HTTPException(status_code=400, detail="Job content is required")
    
    file_bytes = await cv_file.read()
    mime_type = mimetypes.guess_type(cv_file.filename)[0]
    if mime_type is None:
        raise HTTPException(status_code=400, detail="Could not determine file type")
    try:
        cv_content = extract_text_from_file(file_bytes, mime_type)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    logger.info(f"Received CV file: {cv_file.filename}, size: {len(cv_content)} bytes, type: {mime_type}")
    logger.info(f"Job content length: {len(job_content)}")
    
    # Create prompt for LLM
    prompt = f"""
Analyze the following CV content against the job description and provide a detailed analysis in JSON format.

CV Content:
{cv_content}

Job Description:
{job_content}

Please respond with a JSON object containing:
- score: integer (0-100)
- summary: string
- strengths: array of strings
- gaps: array of strings
- skills: array of objects with "name" and "status" (strong, partial, missing)
- experience: array of objects with "category" and "match" (0-100)
- recommendations: array of strings

Ensure the response is valid JSON.
"""
    
    logger.info("Creating prompt for LLM")
    
    try:
        client = get_llm_client()
        logger.info("Calling LLM for analysis")
        response = client.invoke([HumanMessage(content=prompt)]).content
        logger.info(f"LLM response: {response}")
        logger.info("LLM response received, parsing JSON")
        
        # Extract JSON from markdown code block if present
        json_match = re.search(r'```json\s*(\{.*\})\s*```', response, re.DOTALL)
        if json_match:
            response = json_match.group(1)
        elif response.startswith('```json'):
            response = response[7:].strip()
            if response.endswith('```'):
                response = response[:-3].strip()
        
        analysis = json.loads(response)
        logger.info(f"Analysis completed with score: {analysis.get('score', 'N/A')}")
        return analysis
    except Exception as e:
        logger.error(f"LLM analysis failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"LLM analysis failed: {str(e)}")

# Generated by Copilot