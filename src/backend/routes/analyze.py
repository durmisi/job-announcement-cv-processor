from fastapi import APIRouter, HTTPException, UploadFile, File, Form
import json
from llm.factory import get_llm_client

router = APIRouter()

@router.post("/analyze")
async def analyze_cv(cv_file: UploadFile = File(...), job_content: str = Form(...)):
    if not cv_file:
        raise HTTPException(status_code=400, detail="CV file is required")
    if not job_content.strip():
        raise HTTPException(status_code=400, detail="Job content is required")
    
    # Read CV content
    cv_content = (await cv_file.read()).decode("utf-8")
    
    # Create prompt for LLM
    prompt = f"""
Analyze the following CV content against the job description and provide a detailed analysis in JSON format.

CV Content:
{cv_content}

Job Description:
{job_content}

Please respond with a JSON object containing:
- score: integer (0-100)
- summary: string
- strengths: array of strings
- gaps: array of strings
- skills: array of objects with "name" and "status" (strong, partial, missing)
- experience: array of objects with "category" and "match" (0-100)
- recommendations: array of strings

Ensure the response is valid JSON.
"""
    
    try:
        client = get_llm_client()
        response = client.generate_response(prompt)
        analysis = json.loads(response)
        return analysis
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM analysis failed: {str(e)}")

# Generated by Copilot