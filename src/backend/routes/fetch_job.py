from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from playwright.sync_api import sync_playwright
from llm.factory import get_llm_client
import logging

router = APIRouter()

logger = logging.getLogger(__name__)

class FetchJobRequest(BaseModel):
    url: str

@router.post("/fetch-job")
def fetch_job(request: FetchJobRequest):
    url = request.url
    logger.info(f"Starting job fetch for URL: {url}")
    if not url.startswith(('http://', 'https://')):
        logger.warning(f"Invalid URL provided: {url}")
        raise HTTPException(status_code=400, detail="Invalid URL")
    try:
        with sync_playwright() as p:
            logger.info("Launching browser with Playwright")
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            logger.info(f"Navigating to URL: {url}")
            page.goto(url, timeout=30000)
            page.wait_for_load_state('networkidle', timeout=10000)
            
            # Scroll to bottom to load all lazy content
            logger.info("Scrolling to load lazy content")
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(2000)
            page.wait_for_load_state('networkidle', timeout=5000)
            
            # Get the full HTML content after all loading
            logger.info("Extracting page content")
            content = page.locator('body').text_content()
            browser.close()
        
        # Use LLM to extract job announcement as markdown
        logger.info("Processing content with LLM")
        client = get_llm_client()
        prompt = f"""
Extract the main job announcement content from the webpage text provided below. Remove headers, footers, navigation, ads, and any unrelated content. Output the extracted content as clean Markdown, preserving the original structure, language, and formatting without reorganizing or adding sections. Do not summarize or shorten; provide the full extracted content.

CONTENT INPUT:
{content}
"""
        extracted_content = client.generate_response(prompt)
        logger.info("Job fetch and processing completed successfully")
        
        return {"content": extracted_content}
    except Exception as e:
        logger.error(f"Failed to fetch or process URL: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Failed to fetch or process URL: {str(e)}")

# Generated by Copilot